{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e03cfa8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available.  Training on CPU ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "%run DataPrep.ipynb\n",
    "%run SentimentCNN_model.ipynb\n",
    "%run TrainTestSentimentCNN.ipynb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a797fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_data = pd.read_csv('Data/combined_reviews_data.csv', encoding='latin-1', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b741e615",
   "metadata": {},
   "source": [
    "### Preprocess and Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b25c21",
   "metadata": {},
   "source": [
    "#### Initial preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4368b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_list = reviews_data['review'].to_list() # get reviews in a list from the pd.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9cd5d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the reviews in accordance to the preprocess function.\n",
    "preprocessed_reviews_list = [preprocess(review) for review in reviews_list] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afe949a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the reviews together and tokenize the individual words.\n",
    "tokenized_lemmatized_text = tokenize_lemmatize(' '.join(preprocessed_reviews_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0943ab58",
   "metadata": {},
   "source": [
    "#### Encoding words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dcb3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating look up table for encoding words to integers, while getting back their frequency or occurrence.\n",
    "word_count, vocab_int, int_vocab = create_lookup_tables(tokenized_lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78520ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_ints = []\n",
    "for review in preprocessed_reviews_list:\n",
    "    reviews_ints.append([vocab_int[word] for word in tokenize_lemmatize(review)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275fc301",
   "metadata": {},
   "source": [
    "#### Padding Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5276bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "\n",
    "features = pad_features(reviews_ints, seq_length)\n",
    "sentiments = np.array(reviews_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "538d8580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(67500, 40) \n",
      "Validation set: \t(3750, 40) \n",
      "Test set: \t\t(3750, 40)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.9\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "\n",
    "split_idx = int(len(features)*split_frac)\n",
    "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
    "train_y, remaining_y = sentiments[:split_idx], sentiments[split_idx:]\n",
    "\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8876c626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 50\n",
    "\n",
    "# make sure the SHUFFLE your training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb4185df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "sample = dataiter.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b5581c",
   "metadata": {},
   "source": [
    "#### Setting Hyperparameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e726b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "vocab_size = len(vocab_int) # + 1 for the 0 padding + our word tokens\n",
    "embedding_size = 300\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00ac2498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed = nn.Embedding(vocab_size, embedding_size)\n",
    "# e = embed(sample[0]).reshape(50, seq_length, embedding_size)\n",
    "# conv1 = nn.Conv1d(40, 64, 3)\n",
    "# x = F.relu(conv1(e))\n",
    "# print(\"conv1: \", x.shape)\n",
    "# conv2 = nn.Conv1d(64, 32, 3)\n",
    "# x = F.relu(conv2(x))\n",
    "# print(\"conv2: \",x.shape)\n",
    "# pool1 = nn.MaxPool1d(3,3)\n",
    "# x = pool1(F.relu(x))\n",
    "# print(\"pool1: \",x.shape)\n",
    "# conv3 = nn.Conv1d(32, 16, 3)\n",
    "# x = conv3(x)\n",
    "# print(\"conv3: \",x.shape)\n",
    "# conv4 = nn.Conv1d(16, 8, 3)\n",
    "# x = conv4(x)\n",
    "# print(\"conv4: \",x.shape)\n",
    "# avgpool = nn.AvgPool1d(94)\n",
    "# x = avgpool(x)\n",
    "# print(\"avgpool: \",x.shape)\n",
    "# x = x.view(50, -1)\n",
    "# print(\"flattened: \", x.shape)\n",
    "# fc = nn.Linear(8, 1)\n",
    "# x = fc(x)\n",
    "# print(\"final output shape\", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6d4cc9",
   "metadata": {},
   "source": [
    "#### Instantiate model with parameters (currently only working with seq_length = 40, batchsize=50 and output_size=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6f2e20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentCNN(\n",
      "  (embedding): Embedding(139579, 300)\n",
      "  (conv1): Conv1d(40, 64, kernel_size=(3,), stride=(1,))\n",
      "  (conv2): Conv1d(64, 32, kernel_size=(3,), stride=(1,))\n",
      "  (pool1): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(32, 16, kernel_size=(3,), stride=(1,))\n",
      "  (conv4): Conv1d(16, 8, kernel_size=(3,), stride=(1,))\n",
      "  (avgpool): AvgPool1d(kernel_size=(94,), stride=(94,), padding=(0,))\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SentimentCNN(vocab_size, output_size, embedding_size, batch_size, seq_length)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed26723d",
   "metadata": {},
   "source": [
    "### Train or Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351387a8",
   "metadata": {},
   "source": [
    "#### Specifying learning_rate, Loss functions and Optimizer for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba37ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001 # learning rate to be used for the optimizer.\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510a6f05",
   "metadata": {},
   "source": [
    "#### Import the train model function from TrainTestSentimentCNN ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fc8529",
   "metadata": {},
   "source": [
    "##### TRAIN MODEL: UNCOMMENT CELL BELOW TO RUN TRAINING PROCEDURE. \n",
    "Current model trains for 5 epochs and saves the model params whenever validation loss hits a min value after an epoch of training. That pre-trained model can then be used for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7155ae2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.583905 \tValidation Loss: 0.466764\n",
      "Validation loss decreased (inf --> 0.466764).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.422067 \tValidation Loss: 0.432903\n",
      "Validation loss decreased (0.466764 --> 0.432903).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.338804 \tValidation Loss: 0.410755\n",
      "Validation loss decreased (0.432903 --> 0.410755).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.253583 \tValidation Loss: 0.385520\n",
      "Validation loss decreased (0.410755 --> 0.385520).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.179707 \tValidation Loss: 0.399031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_sentimentCNN(model, train_loader, valid_loader, criterion, optimizer, lr, save_model_as='Sentiment_CNN_v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1b93aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model with the trained parameters/weights.\n",
    "model.load_state_dict(torch.load('Sentiment_CNN_v4.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76452dd1",
   "metadata": {},
   "source": [
    "##### TEST MODEL: UNCOMMENT CELL BELOW TO RUN TEST PROCEDURE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91757699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sentimentCNN(model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277c1f5f",
   "metadata": {},
   "source": [
    "### Inference \n",
    "Looking at the model's performance against any input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8a949f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_texts = [\"poor quality signal given by the device package did not arrive I am not happy with this\", \n",
    "             \"I actually liked that part of the feature It was surprising in a good way and I will surely go back again\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08438898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, new_texts, sequence_length=40):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # tokenize review\n",
    "    new_texts_ints = [word_to_int(text, vocab_int) for text in new_texts]\n",
    "    \n",
    "    # pad tokenized sequence\n",
    "    seq_length=sequence_length\n",
    "    features = pad_features(new_texts_ints, seq_length)\n",
    "    # make the batch size of the features presented to be teh size the model was trained on. Default = 50.\n",
    "    if features.shape[0] < 50:\n",
    "        new_features = np.zeros((50 - features.shape[0], seq_length), dtype=int)\n",
    "        features = np.concatenate((features, new_features), axis=0)\n",
    "    else:\n",
    "        features = features[:50]\n",
    "    # convert to tensor to pass into your model\n",
    "    feature_tensor = torch.from_numpy(features)\n",
    "    \n",
    "    # get the output from the model\n",
    "    output = model(feature_tensor)\n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())\n",
    "    pred = list(pred[:len(new_texts)])\n",
    "    sentiment_mapping = {1: \"postive\", 0: \"negative\"}\n",
    "    \n",
    "    model_response = []\n",
    "    for i in range(0, len(pred)):\n",
    "        if pred[i] == 1:\n",
    "            model_response.append(\"positive\")\n",
    "        else:\n",
    "            model_response.append(\"negative\")\n",
    "    \n",
    "    response_dict = {}\n",
    "    for i in range(0, len(pred)):\n",
    "        response_dict[new_texts[i]] = model_response[i]\n",
    "    \n",
    "    return response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "825624e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poor quality signal given by the device package did not arrive I am not happy with this': 'negative',\n",
       " 'I actually liked that part of the feature It was surprising in a good way and I will surely go back again': 'positive'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, new_texts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
